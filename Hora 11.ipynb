{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00059: early stopping\n",
      "44/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 80.0607 - mean_absolute_error: 60.8827\n",
      "Model evaluation  [71.72878196022727, 60.882736]\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00029: early stopping\n",
      "43/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 13ms/sample - loss: 59.8516 - mean_absolute_error: 47.3364\n",
      "Model evaluation  [61.934871584870095, 47.3364]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import HoverTool\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input,Dense, Subtract, Add, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.linear_model import Lasso\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "data = pd.read_excel(\"C:/Users/ERIC/Desktop/PML-06MTP-115/06MTP 01012020.xlsm\", 1)\n",
    "\n",
    "# Training dataset\n",
    "x = data.iloc[:87, [1,12,36,60]].values\n",
    "y = data.iloc[:87, 84].values\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 0) #try random_state = 42\n",
    "\n",
    "#Standarization of the data\n",
    "'''\n",
    "sc = StandardScaler()\n",
    "std_x_train = sc.fit_transform(x_train)\n",
    "std_x_test = sc.fit_transform(x_test)\n",
    "'''\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x = min_max_scaler.fit_transform(x)\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(x.shape[1],))\n",
    "    layer_in_drop = Dropout(0.3)\n",
    "\n",
    "    hidden_layer = Dense(100, activation = 'relu', kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(input_tensor) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop = Dropout(0.3)\n",
    "\n",
    "    hidden_layer1 = Dense(100, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop1 = Dropout(0.3)\n",
    "    \n",
    "    hidden_layer2 = Dense(50, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer1) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop2 = Dropout(0.3)\n",
    "    \n",
    "    hidden_layer3 = Dense(25, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer2) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop3 = Dropout(0.3)\n",
    "    '''\n",
    "    hidden_layer4 = Dense(25, activation = 'relu', kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer3) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop4 = Dropout(0.3)\n",
    "    '''\n",
    "    output_tensor = Dense(1)(hidden_layer3)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer= Adam(0.003),  loss='mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "n_split=2\n",
    " \n",
    "for train_index,test_index in KFold(n_split).split(x):\n",
    "    x_train,x_test=x[train_index],x[test_index]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    model= create_model()\n",
    "    monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-3, patience = 5, verbose = 1, mode = 'auto', \n",
    "                        restore_best_weights = True)\n",
    "    history = model.fit(x_train,\n",
    "          y_train,\n",
    "          #validation_data = (x_test, y_test),\n",
    "          callbacks = [monitor],\n",
    "          epochs=200,\n",
    "          batch_size = 3,\n",
    "          validation_split = 0.2,\n",
    "          verbose=0)\n",
    "    print('Model evaluation ',model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 60.52274257288377\n",
      "R^2 on training set is 0.19431146212604133\n",
      "R^2 on testing set is -0.02038776435259737\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Real Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354.166656</td>\n",
       "      <td>313.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>355.585297</td>\n",
       "      <td>309.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268.106079</td>\n",
       "      <td>274.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>344.842346</td>\n",
       "      <td>314.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374.545197</td>\n",
       "      <td>347.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>365.596619</td>\n",
       "      <td>296.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>376.402618</td>\n",
       "      <td>314.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>394.844971</td>\n",
       "      <td>215.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>363.061462</td>\n",
       "      <td>323.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>269.152527</td>\n",
       "      <td>243.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>341.733002</td>\n",
       "      <td>336.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>352.328217</td>\n",
       "      <td>341.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>345.173401</td>\n",
       "      <td>238.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>348.310974</td>\n",
       "      <td>335.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>353.542603</td>\n",
       "      <td>306.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>320.305145</td>\n",
       "      <td>180.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>254.967484</td>\n",
       "      <td>188.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>312.567108</td>\n",
       "      <td>345.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>364.823792</td>\n",
       "      <td>416.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>397.061798</td>\n",
       "      <td>323.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>356.311981</td>\n",
       "      <td>280.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>360.744171</td>\n",
       "      <td>229.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>340.576385</td>\n",
       "      <td>301.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>269.563873</td>\n",
       "      <td>287.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>341.961884</td>\n",
       "      <td>329.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>361.736145</td>\n",
       "      <td>353.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>378.012085</td>\n",
       "      <td>359.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>395.934021</td>\n",
       "      <td>373.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>418.017639</td>\n",
       "      <td>342.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>392.227509</td>\n",
       "      <td>368.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>309.110657</td>\n",
       "      <td>305.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>259.922363</td>\n",
       "      <td>328.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>355.703339</td>\n",
       "      <td>425.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>396.911102</td>\n",
       "      <td>427.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>403.812988</td>\n",
       "      <td>480.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>419.079102</td>\n",
       "      <td>349.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>377.561310</td>\n",
       "      <td>355.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>267.596344</td>\n",
       "      <td>309.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>344.617950</td>\n",
       "      <td>337.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>353.973267</td>\n",
       "      <td>366.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>410.170074</td>\n",
       "      <td>374.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>404.147003</td>\n",
       "      <td>361.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>431.787170</td>\n",
       "      <td>375.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Real Value\n",
       "0   354.166656      313.17\n",
       "1   355.585297      309.27\n",
       "2   268.106079      274.60\n",
       "3   344.842346      314.26\n",
       "4   374.545197      347.46\n",
       "5   365.596619      296.43\n",
       "6   376.402618      314.67\n",
       "7   394.844971      215.91\n",
       "8   363.061462      323.94\n",
       "9   269.152527      243.88\n",
       "10  341.733002      336.00\n",
       "11  352.328217      341.81\n",
       "12  345.173401      238.45\n",
       "13  348.310974      335.61\n",
       "14  353.542603      306.14\n",
       "15  320.305145      180.71\n",
       "16  254.967484      188.74\n",
       "17  312.567108      345.83\n",
       "18  364.823792      416.90\n",
       "19  397.061798      323.08\n",
       "20  356.311981      280.32\n",
       "21  360.744171      229.53\n",
       "22  340.576385      301.54\n",
       "23  269.563873      287.47\n",
       "24  341.961884      329.87\n",
       "25  361.736145      353.96\n",
       "26  378.012085      359.32\n",
       "27  395.934021      373.60\n",
       "28  418.017639      342.68\n",
       "29  392.227509      368.14\n",
       "30  309.110657      305.10\n",
       "31  259.922363      328.67\n",
       "32  355.703339      425.41\n",
       "33  396.911102      427.24\n",
       "34  403.812988      480.62\n",
       "35  419.079102      349.80\n",
       "36  377.561310      355.23\n",
       "37  267.596344      309.25\n",
       "38  344.617950      337.47\n",
       "39  353.973267      366.41\n",
       "40  410.170074      374.80\n",
       "41  404.147003      361.61\n",
       "42  431.787170      375.07"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "pred_train = model.predict(x_train)\n",
    "print(\"R^2 on training set is {}\".format(r2_score(y_train, pred_train)))\n",
    "print(\"R^2 on testing set is {}\".format(r2_score(y_test, pred)))\n",
    "\n",
    "pred = pd.DataFrame(pred)\n",
    "pred.columns = ['Prediction']\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.columns = ['Real Value']\n",
    "results = pd.concat([pred,y_test], axis =1)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2849a5cde88>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "plt.figure()\n",
    "plt.plot(loss_values, 'k', label = 'training_loss')\n",
    "plt.plot(val_loss_values, 'r', label = 'val training loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>308.218597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>243.920822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310.512482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333.191223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>347.438171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>409.361084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>399.805054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>433.143646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>400.329102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>401.291351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Forecast\n",
       "0   308.218597\n",
       "1   243.920822\n",
       "2   310.512482\n",
       "3   333.191223\n",
       "4   347.438171\n",
       "..         ...\n",
       "74  409.361084\n",
       "75  399.805054\n",
       "76  433.143646\n",
       "77  400.329102\n",
       "78  401.291351\n",
       "\n",
       "[79 rows x 1 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_f = data.iloc[10:, [1,12,36,60]].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_f = min_max_scaler.fit_transform(x_f)\n",
    "\n",
    "forecast = model.predict(x_f)\n",
    "forecast = pd.DataFrame(forecast)\n",
    "forecast.columns = ['Forecast']\n",
    "forecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
