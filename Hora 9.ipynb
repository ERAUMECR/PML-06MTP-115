{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00016: early stopping\n",
      "44/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 89.4473 - mean_absolute_error: 66.6333\n",
      "Model evaluation  [82.14226185191761, 66.63331]\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00019: early stopping\n",
      "43/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 8ms/sample - loss: 84.4045 - mean_absolute_error: 64.1887\n",
      "Model evaluation  [79.06915105775346, 64.18866]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import HoverTool\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input,Dense, Subtract, Add, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.linear_model import Lasso\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "data = pd.read_excel(\"C:/Users/ERIC/Desktop/PML-06MTP-115/06MTP 01012020.xlsm\", 1)\n",
    "\n",
    "# Training dataset\n",
    "x = data.iloc[:87, [1,10,34,58]].values\n",
    "y = data.iloc[:87, 82].values\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 0) #try random_state = 42\n",
    "\n",
    "#Standarization of the data\n",
    "'''\n",
    "sc = StandardScaler()\n",
    "std_x_train = sc.fit_transform(x_train)\n",
    "std_x_test = sc.fit_transform(x_test)\n",
    "'''\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x = min_max_scaler.fit_transform(x)\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(x.shape[1],))\n",
    "    layer_drop = Dropout(0.3)\n",
    "\n",
    "    hidden_layer = Dense(100, activation = 'relu', kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(input_tensor) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop = Dropout(0.5)\n",
    "\n",
    "    hidden_layer1 = Dense(100, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop1 = Dropout(0.5)\n",
    "    \n",
    "    hidden_layer2 = Dense(50, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer1) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop2 = Dropout(0.5)\n",
    "\n",
    "    hidden_layer3 = Dense(25, activation = 'relu', kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer2) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop3 = Dropout(0.5)\n",
    "    \n",
    "    output_tensor = Dense(1)(hidden_layer3)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer= Adam(0.003),  loss='mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "n_split=2\n",
    " \n",
    "for train_index,test_index in KFold(n_split).split(x):\n",
    "    x_train,x_test=x[train_index],x[test_index]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    model= create_model()\n",
    "    monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-3, patience = 5, verbose = 1, mode = 'auto', \n",
    "                        restore_best_weights = True)\n",
    "    history = model.fit(x_train,\n",
    "          y_train,\n",
    "          #validation_data = (x_test, y_test),\n",
    "          callbacks = [monitor],\n",
    "          epochs=200,\n",
    "          batch_size = 3,\n",
    "          validation_split = 0.2,\n",
    "          verbose=0)\n",
    "    print('Model evaluation ',model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 74.64933386261521\n",
      "R^2 on training set is 0.369721073469644\n",
      "R^2 on testing set is 0.05138929057001829\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Real Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>414.097076</td>\n",
       "      <td>364.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>397.989258</td>\n",
       "      <td>344.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283.424774</td>\n",
       "      <td>295.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>345.422699</td>\n",
       "      <td>312.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>388.583466</td>\n",
       "      <td>354.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>393.959564</td>\n",
       "      <td>317.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>402.504822</td>\n",
       "      <td>333.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>430.753204</td>\n",
       "      <td>325.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>408.600616</td>\n",
       "      <td>333.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>291.966003</td>\n",
       "      <td>266.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>344.536316</td>\n",
       "      <td>312.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>383.356049</td>\n",
       "      <td>340.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>384.430908</td>\n",
       "      <td>274.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>398.626648</td>\n",
       "      <td>348.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>397.475769</td>\n",
       "      <td>314.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>343.647858</td>\n",
       "      <td>288.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>261.785095</td>\n",
       "      <td>111.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>238.098129</td>\n",
       "      <td>307.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>389.018463</td>\n",
       "      <td>439.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>416.839417</td>\n",
       "      <td>295.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>389.566376</td>\n",
       "      <td>294.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>393.310791</td>\n",
       "      <td>275.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>356.988739</td>\n",
       "      <td>311.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>268.227234</td>\n",
       "      <td>271.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>323.120514</td>\n",
       "      <td>329.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>387.986816</td>\n",
       "      <td>476.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>397.253235</td>\n",
       "      <td>361.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>415.835754</td>\n",
       "      <td>451.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>434.176971</td>\n",
       "      <td>363.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>416.053345</td>\n",
       "      <td>363.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>330.313202</td>\n",
       "      <td>336.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>252.893692</td>\n",
       "      <td>344.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>362.937012</td>\n",
       "      <td>521.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>405.239685</td>\n",
       "      <td>500.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>420.691925</td>\n",
       "      <td>515.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>444.793823</td>\n",
       "      <td>506.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>411.733612</td>\n",
       "      <td>423.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>282.866333</td>\n",
       "      <td>323.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>317.474945</td>\n",
       "      <td>355.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>380.060822</td>\n",
       "      <td>355.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>428.808960</td>\n",
       "      <td>362.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>444.926758</td>\n",
       "      <td>355.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>532.897888</td>\n",
       "      <td>402.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Real Value\n",
       "0   414.097076      364.98\n",
       "1   397.989258      344.14\n",
       "2   283.424774      295.53\n",
       "3   345.422699      312.07\n",
       "4   388.583466      354.18\n",
       "5   393.959564      317.09\n",
       "6   402.504822      333.68\n",
       "7   430.753204      325.60\n",
       "8   408.600616      333.61\n",
       "9   291.966003      266.87\n",
       "10  344.536316      312.92\n",
       "11  383.356049      340.89\n",
       "12  384.430908      274.51\n",
       "13  398.626648      348.13\n",
       "14  397.475769      314.07\n",
       "15  343.647858      288.78\n",
       "16  261.785095      111.54\n",
       "17  238.098129      307.44\n",
       "18  389.018463      439.60\n",
       "19  416.839417      295.89\n",
       "20  389.566376      294.64\n",
       "21  393.310791      275.51\n",
       "22  356.988739      311.16\n",
       "23  268.227234      271.55\n",
       "24  323.120514      329.90\n",
       "25  387.986816      476.90\n",
       "26  397.253235      361.87\n",
       "27  415.835754      451.86\n",
       "28  434.176971      363.15\n",
       "29  416.053345      363.92\n",
       "30  330.313202      336.70\n",
       "31  252.893692      344.77\n",
       "32  362.937012      521.29\n",
       "33  405.239685      500.72\n",
       "34  420.691925      515.29\n",
       "35  444.793823      506.82\n",
       "36  411.733612      423.61\n",
       "37  282.866333      323.85\n",
       "38  317.474945      355.84\n",
       "39  380.060822      355.60\n",
       "40  428.808960      362.31\n",
       "41  444.926758      355.44\n",
       "42  532.897888      402.97"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "pred_train = model.predict(x_train)\n",
    "print(\"R^2 on training set is {}\".format(r2_score(y_train, pred_train)))\n",
    "print(\"R^2 on testing set is {}\".format(r2_score(y_test, pred)))\n",
    "\n",
    "pred = pd.DataFrame(pred)\n",
    "pred.columns = ['Prediction']\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.columns = ['Real Value']\n",
    "results = pd.concat([pred,y_test], axis =1)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x199044e4dc8>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "plt.figure()\n",
    "plt.plot(loss_values, 'k', label = 'training_loss')\n",
    "plt.plot(val_loss_values, 'r', label = 'val training loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>326.624176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>254.076447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310.660004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>335.312958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>368.017975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>402.317413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>419.975342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>525.693115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>458.030762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>450.518768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Forecast\n",
       "0   326.624176\n",
       "1   254.076447\n",
       "2   310.660004\n",
       "3   335.312958\n",
       "4   368.017975\n",
       "..         ...\n",
       "74  402.317413\n",
       "75  419.975342\n",
       "76  525.693115\n",
       "77  458.030762\n",
       "78  450.518768\n",
       "\n",
       "[79 rows x 1 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_f = data.iloc[10:, [1,10,34,58]].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_f = min_max_scaler.fit_transform(x_f)\n",
    "\n",
    "forecast = model.predict(x_f)\n",
    "forecast = pd.DataFrame(forecast)\n",
    "forecast.columns = ['Forecast']\n",
    "forecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
