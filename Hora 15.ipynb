{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n",
      "44/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 79.8951 - mean_absolute_error: 75.7435\n",
      "Model evaluation  [88.98170679265803, 75.74352]\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00014: early stopping\n",
      "43/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 76.6881 - mean_absolute_error: 60.6154\n",
      "Model evaluation  [76.54645112503407, 60.615353]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import HoverTool\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input,Dense, Subtract, Add, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.linear_model import Lasso\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "data = pd.read_excel(\"C:/Users/ERIC/Desktop/PML-06MTP-115/06MTP 01012020.xlsm\", 1)\n",
    "\n",
    "# Training dataset\n",
    "x = data.iloc[:87, [1,16,40,64]].values\n",
    "y = data.iloc[:87, 88].values\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 0) #try random_state = 42\n",
    "\n",
    "#Standarization of the data\n",
    "'''\n",
    "sc = StandardScaler()\n",
    "std_x_train = sc.fit_transform(x_train)\n",
    "std_x_test = sc.fit_transform(x_test)\n",
    "'''\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x = min_max_scaler.fit_transform(x)\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(x.shape[1],))\n",
    "    layer_in_drop = Dropout(0.5)\n",
    "\n",
    "    hidden_layer = Dense(100, activation = 'relu', kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(input_tensor) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop = Dropout(0.5)\n",
    "\n",
    "    hidden_layer1 = Dense(100, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop1 = Dropout(0.5)\n",
    "    \n",
    "    hidden_layer2 = Dense(50, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer1) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop2 = Dropout(0.5)\n",
    "    \n",
    "    hidden_layer3 = Dense(25, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer2) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop3 = Dropout(0.5)\n",
    "    '''\n",
    "    hidden_layer4 = Dense(25, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer3) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop4 = Dropout(0.5)\n",
    "    '''\n",
    "    output_tensor = Dense(1)(hidden_layer3)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer= Adam(0.001),  loss='mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "n_split=2\n",
    " \n",
    "for train_index,test_index in KFold(n_split).split(x):\n",
    "    x_train,x_test=x[train_index],x[test_index]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    model= create_model()\n",
    "    monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-3, patience = 5, verbose = 1, mode = 'auto', \n",
    "                        restore_best_weights = True)\n",
    "    history = model.fit(x_train,\n",
    "          y_train,\n",
    "          #validation_data = (x_test, y_test),\n",
    "          callbacks = [monitor],\n",
    "          epochs=200,\n",
    "          batch_size = 3,\n",
    "          validation_split = 0.2,\n",
    "          verbose=0)\n",
    "    print('Model evaluation ',model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 81.4775610130572\n",
      "R^2 on training set is -0.34843551095457714\n",
      "R^2 on testing set is 0.1323784905114448\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Real Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>341.732666</td>\n",
       "      <td>313.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>332.453400</td>\n",
       "      <td>300.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276.053864</td>\n",
       "      <td>212.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>289.985809</td>\n",
       "      <td>312.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356.576752</td>\n",
       "      <td>350.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>351.020386</td>\n",
       "      <td>289.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>350.066864</td>\n",
       "      <td>275.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>371.476776</td>\n",
       "      <td>326.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>341.419312</td>\n",
       "      <td>303.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>267.943359</td>\n",
       "      <td>262.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>282.421631</td>\n",
       "      <td>340.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>329.977417</td>\n",
       "      <td>476.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>299.923157</td>\n",
       "      <td>156.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>325.734192</td>\n",
       "      <td>352.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>332.862030</td>\n",
       "      <td>280.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>306.302917</td>\n",
       "      <td>180.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>258.294495</td>\n",
       "      <td>141.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>191.050659</td>\n",
       "      <td>449.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>360.290375</td>\n",
       "      <td>345.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>355.588531</td>\n",
       "      <td>362.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>343.452820</td>\n",
       "      <td>289.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>340.509979</td>\n",
       "      <td>230.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>321.169373</td>\n",
       "      <td>296.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>270.112427</td>\n",
       "      <td>290.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>279.875000</td>\n",
       "      <td>325.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>325.713837</td>\n",
       "      <td>469.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>360.533081</td>\n",
       "      <td>382.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>403.167664</td>\n",
       "      <td>407.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>429.690216</td>\n",
       "      <td>383.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>415.003418</td>\n",
       "      <td>367.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>330.827789</td>\n",
       "      <td>312.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>239.500381</td>\n",
       "      <td>332.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>325.713837</td>\n",
       "      <td>489.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>387.194427</td>\n",
       "      <td>498.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>415.667633</td>\n",
       "      <td>390.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>414.934174</td>\n",
       "      <td>398.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>366.358856</td>\n",
       "      <td>357.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>301.250916</td>\n",
       "      <td>316.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>291.991089</td>\n",
       "      <td>336.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>333.975708</td>\n",
       "      <td>404.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>413.010101</td>\n",
       "      <td>403.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>428.502350</td>\n",
       "      <td>375.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>434.486115</td>\n",
       "      <td>568.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Real Value\n",
       "0   341.732666      313.88\n",
       "1   332.453400      300.57\n",
       "2   276.053864      212.04\n",
       "3   289.985809      312.98\n",
       "4   356.576752      350.64\n",
       "5   351.020386      289.57\n",
       "6   350.066864      275.98\n",
       "7   371.476776      326.89\n",
       "8   341.419312      303.60\n",
       "9   267.943359      262.17\n",
       "10  282.421631      340.76\n",
       "11  329.977417      476.41\n",
       "12  299.923157      156.18\n",
       "13  325.734192      352.56\n",
       "14  332.862030      280.94\n",
       "15  306.302917      180.63\n",
       "16  258.294495      141.15\n",
       "17  191.050659      449.58\n",
       "18  360.290375      345.85\n",
       "19  355.588531      362.29\n",
       "20  343.452820      289.91\n",
       "21  340.509979      230.53\n",
       "22  321.169373      296.82\n",
       "23  270.112427      290.11\n",
       "24  279.875000      325.26\n",
       "25  325.713837      469.46\n",
       "26  360.533081      382.25\n",
       "27  403.167664      407.86\n",
       "28  429.690216      383.53\n",
       "29  415.003418      367.89\n",
       "30  330.827789      312.16\n",
       "31  239.500381      332.02\n",
       "32  325.713837      489.46\n",
       "33  387.194427      498.43\n",
       "34  415.667633      390.15\n",
       "35  414.934174      398.65\n",
       "36  366.358856      357.69\n",
       "37  301.250916      316.28\n",
       "38  291.991089      336.13\n",
       "39  333.975708      404.61\n",
       "40  413.010101      403.26\n",
       "41  428.502350      375.56\n",
       "42  434.486115      568.98"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "pred_train = model.predict(x_train)\n",
    "print(\"R^2 on training set is {}\".format(r2_score(y_train, pred_train)))\n",
    "print(\"R^2 on testing set is {}\".format(r2_score(y_test, pred)))\n",
    "\n",
    "pred = pd.DataFrame(pred)\n",
    "pred.columns = ['Prediction']\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.columns = ['Real Value']\n",
    "results = pd.concat([pred,y_test], axis =1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d531188888>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "plt.figure()\n",
    "plt.plot(loss_values, 'k', label = 'training_loss')\n",
    "plt.plot(val_loss_values, 'r', label = 'val training loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302.857727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253.637405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>249.739502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>297.542053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>329.766754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>405.522705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>419.224335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>428.127716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>390.294678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>407.064636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Forecast\n",
       "0   302.857727\n",
       "1   253.637405\n",
       "2   249.739502\n",
       "3   297.542053\n",
       "4   329.766754\n",
       "..         ...\n",
       "74  405.522705\n",
       "75  419.224335\n",
       "76  428.127716\n",
       "77  390.294678\n",
       "78  407.064636\n",
       "\n",
       "[79 rows x 1 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_f = data.iloc[10:, [1,16,40,64]].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_f = min_max_scaler.fit_transform(x_f)\n",
    "\n",
    "forecast = model.predict(x_f)\n",
    "forecast = pd.DataFrame(forecast)\n",
    "forecast.columns = ['Forecast']\n",
    "forecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
