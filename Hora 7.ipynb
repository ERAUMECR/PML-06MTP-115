{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00020: early stopping\n",
      "44/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 63.6502 - mean_absolute_error: 44.5693\n",
      "Model evaluation  [62.20593192360618, 44.569286]\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00047: early stopping\n",
      "43/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 8ms/sample - loss: 75.7862 - mean_absolute_error: 50.0003\n",
      "Model evaluation  [64.82107756858649, 50.00034]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import HoverTool\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input,Dense, Subtract, Add, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.linear_model import Lasso\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "data = pd.read_excel(\"C:/Users/ERIC/Desktop/PML-06MTP-115/06MTP 01012020.xlsm\", 1)\n",
    "\n",
    "# Training dataset\n",
    "x = data.iloc[:87, [1,8,32,56]].values\n",
    "y = data.iloc[:87, 80].values\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 0) #try random_state = 42\n",
    "\n",
    "#Standarization of the data\n",
    "'''\n",
    "sc = StandardScaler()\n",
    "std_x_train = sc.fit_transform(x_train)\n",
    "std_x_test = sc.fit_transform(x_test)\n",
    "'''\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x = min_max_scaler.fit_transform(x)\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(x.shape[1],))\n",
    "    #layer_drop = Dropout(0.3)\n",
    "\n",
    "    hidden_layer = Dense(100, activation = 'relu', kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(input_tensor) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop = Dropout(0.5)\n",
    "\n",
    "    hidden_layer1 = Dense(100, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop1 = Dropout(0.5)\n",
    "    \n",
    "    hidden_layer2 = Dense(50, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer1) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop2 = Dropout(0.5)\n",
    "\n",
    "    hidden_layer3 = Dense(50, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer2) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop3 = Dropout(0.5)\n",
    "\n",
    "   \n",
    "    output_tensor = Dense(1)(hidden_layer3)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    model.compile(optimizer= Adam(0.001),  loss='mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "n_split=2\n",
    " \n",
    "for train_index,test_index in KFold(n_split).split(x):\n",
    "    x_train,x_test=x[train_index],x[test_index]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    model= create_model()\n",
    "    monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-3, patience = 5, verbose = 1, mode = 'auto', \n",
    "                        restore_best_weights = True)\n",
    "    history = model.fit(x_train,\n",
    "          y_train,\n",
    "          #validation_data = (x_test, y_test),\n",
    "          callbacks = [monitor],\n",
    "          epochs=200,\n",
    "          batch_size = 3,\n",
    "          validation_split = 0.2,\n",
    "          verbose=0)\n",
    "    print('Model evaluation ',model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 69.34450821871123\n",
      "R^2 on training set is 0.3267776144674358\n",
      "R^2 on testing set is 0.29989595182675755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Real Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368.718201</td>\n",
       "      <td>322.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>355.635132</td>\n",
       "      <td>318.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285.536560</td>\n",
       "      <td>306.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299.099213</td>\n",
       "      <td>299.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>337.917450</td>\n",
       "      <td>298.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>354.387787</td>\n",
       "      <td>306.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>353.361023</td>\n",
       "      <td>323.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>365.823730</td>\n",
       "      <td>331.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>364.746063</td>\n",
       "      <td>341.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>293.031158</td>\n",
       "      <td>280.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>299.784363</td>\n",
       "      <td>291.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>331.343475</td>\n",
       "      <td>340.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>328.550568</td>\n",
       "      <td>240.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>352.616730</td>\n",
       "      <td>355.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>357.097809</td>\n",
       "      <td>355.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>321.129242</td>\n",
       "      <td>281.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>267.957825</td>\n",
       "      <td>170.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>236.952362</td>\n",
       "      <td>273.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>345.074219</td>\n",
       "      <td>537.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>368.991150</td>\n",
       "      <td>467.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>350.825348</td>\n",
       "      <td>278.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>350.267151</td>\n",
       "      <td>299.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>321.213165</td>\n",
       "      <td>304.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>291.255524</td>\n",
       "      <td>268.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>273.223907</td>\n",
       "      <td>294.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>340.430084</td>\n",
       "      <td>361.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>353.692657</td>\n",
       "      <td>351.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>380.257751</td>\n",
       "      <td>333.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>387.337311</td>\n",
       "      <td>351.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>387.174866</td>\n",
       "      <td>339.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>352.706909</td>\n",
       "      <td>395.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>254.299896</td>\n",
       "      <td>375.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>324.611053</td>\n",
       "      <td>420.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>365.554047</td>\n",
       "      <td>511.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>380.622314</td>\n",
       "      <td>359.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>410.873993</td>\n",
       "      <td>415.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>379.516174</td>\n",
       "      <td>395.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>291.254547</td>\n",
       "      <td>341.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>290.877594</td>\n",
       "      <td>342.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>344.905975</td>\n",
       "      <td>487.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>383.954865</td>\n",
       "      <td>577.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>407.453400</td>\n",
       "      <td>409.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>487.415527</td>\n",
       "      <td>543.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Real Value\n",
       "0   368.718201      322.04\n",
       "1   355.635132      318.00\n",
       "2   285.536560      306.88\n",
       "3   299.099213      299.45\n",
       "4   337.917450      298.85\n",
       "5   354.387787      306.37\n",
       "6   353.361023      323.25\n",
       "7   365.823730      331.11\n",
       "8   364.746063      341.83\n",
       "9   293.031158      280.13\n",
       "10  299.784363      291.94\n",
       "11  331.343475      340.98\n",
       "12  328.550568      240.77\n",
       "13  352.616730      355.37\n",
       "14  357.097809      355.08\n",
       "15  321.129242      281.28\n",
       "16  267.957825      170.25\n",
       "17  236.952362      273.64\n",
       "18  345.074219      537.35\n",
       "19  368.991150      467.44\n",
       "20  350.825348      278.51\n",
       "21  350.267151      299.11\n",
       "22  321.213165      304.21\n",
       "23  291.255524      268.57\n",
       "24  273.223907      294.24\n",
       "25  340.430084      361.41\n",
       "26  353.692657      351.52\n",
       "27  380.257751      333.76\n",
       "28  387.337311      351.08\n",
       "29  387.174866      339.10\n",
       "30  352.706909      395.86\n",
       "31  254.299896      375.39\n",
       "32  324.611053      420.70\n",
       "33  365.554047      511.54\n",
       "34  380.622314      359.57\n",
       "35  410.873993      415.61\n",
       "36  379.516174      395.06\n",
       "37  291.254547      341.71\n",
       "38  290.877594      342.48\n",
       "39  344.905975      487.15\n",
       "40  383.954865      577.23\n",
       "41  407.453400      409.04\n",
       "42  487.415527      543.72"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "pred_train = model.predict(x_train)\n",
    "print(\"R^2 on training set is {}\".format(r2_score(y_train, pred_train)))\n",
    "print(\"R^2 on testing set is {}\".format(r2_score(y_test, pred)))\n",
    "\n",
    "pred = pd.DataFrame(pred)\n",
    "pred.columns = ['Prediction']\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.columns = ['Real Value']\n",
    "results = pd.concat([pred,y_test], axis =1)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2770a075cc8>]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "plt.figure()\n",
    "plt.plot(loss_values, 'k', label = 'training_loss')\n",
    "plt.plot(val_loss_values, 'r', label = 'val training loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301.413147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>261.208557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261.991974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280.918243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320.367889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>362.186188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>388.995972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>482.115845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>433.382782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>389.074371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Forecast\n",
       "0   301.413147\n",
       "1   261.208557\n",
       "2   261.991974\n",
       "3   280.918243\n",
       "4   320.367889\n",
       "..         ...\n",
       "74  362.186188\n",
       "75  388.995972\n",
       "76  482.115845\n",
       "77  433.382782\n",
       "78  389.074371\n",
       "\n",
       "[79 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_f = data.iloc[10:, [1,8,32,56]].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_f = min_max_scaler.fit_transform(x_f)\n",
    "\n",
    "forecast = model.predict(x_f)\n",
    "forecast = pd.DataFrame(forecast)\n",
    "forecast.columns = ['Forecast']\n",
    "forecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
