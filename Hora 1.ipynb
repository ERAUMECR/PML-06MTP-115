{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n",
      "29/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 17ms/sample - loss: 74.1898 - mean_absolute_error: 62.3885\n",
      "Model evaluation  [74.1898422241211, 62.38847]\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00028: early stopping\n",
      "29/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 2s 62ms/sample - loss: 82.4391 - mean_absolute_error: 69.3975\n",
      "Model evaluation  [82.43911743164062, 69.39753]\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00032: early stopping\n",
      "29/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 10ms/sample - loss: 79.1532 - mean_absolute_error: 66.7467\n",
      "Model evaluation  [79.15318298339844, 66.74669]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import HoverTool\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input,Dense, Subtract, Add, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.linear_model import Lasso\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# The models were done by hour using all the days of the week\n",
    "data = pd.read_excel(\"C:/Users/ERIC/Desktop/PML-06MTP-115/06MTP 01012020.xlsm\", 1)\n",
    "\n",
    "# dataset for only the first hour\n",
    "x = data.iloc[0:87, [1,2,26,50]].values\n",
    "y = data.iloc[0:87, 74].values\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 0) #try random_state = 42\n",
    "\n",
    "#Standarization of the data\n",
    "'''\n",
    "sc = StandardScaler()\n",
    "std_x_train = sc.fit_transform(x_train)\n",
    "std_x_test = sc.fit_transform(x_test)\n",
    "'''\n",
    "# Normalization of the data\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x = min_max_scaler.fit_transform(x)\n",
    "\n",
    "def create_model():\n",
    "    # The next model is a sequential one, that means the layers are structured sequantially. \n",
    "    \n",
    "    # Input layer with 4 inputs --> day of the week, demand, generation and the forecast for that day\n",
    "    input_tensor = Input(shape=(x.shape[1],))\n",
    "    #layer_drop = Dropout(0.3)\n",
    "    \n",
    "    # First hidden layer --> 100 neurons, relu as activation function...receives the input\n",
    "    hidden_layer = Dense(100, activation = 'relu', kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(input_tensor) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop = Dropout(0.3) # Dropout certain amount of neurons helping to reduce overfitting\n",
    "    #Dropout makes the model does not rely on certain neurons making changes in the information processing\n",
    "    \n",
    "    # Second hidden layer --> 50 neurons, relu as activation function... receives the first hidden layer\n",
    "    hidden_layer1 = Dense(50, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop1 = Dropout(0.3)\n",
    "    \n",
    "    # Third hidden layer --> 50 neurons, relu as activation function... receives the second hidden layer\n",
    "    hidden_layer2 = Dense(50, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer1) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop2 = Dropout(0.3)\n",
    "    \n",
    "    # Fourth hidden layer --> 25 neurons, relu as activation function... receives the third hidden layer\n",
    "    hidden_layer3 = Dense(25, activation = 'relu', kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer2) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop3 = Dropout(0.3)\n",
    "    \n",
    "    # 1 ouput ... Receives the last hidden layer\n",
    "    output_tensor = Dense(1)(hidden_layer3)\n",
    "    \n",
    "    # Here the model is created... receiving the four inputs and 1 output\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    \n",
    "    # Here the model is compiled. Adama is the optimizer in which the learning rate is specified\n",
    "    # The loss function measures helps in optimizing the parameters of the neural networks\n",
    "    # The metrics could be an array of measurements but for this case Mean Absolut error is used because is a Regression \n",
    "    model.compile(optimizer= Adam(0.003),  loss='mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "    return model # the model is returned as a part of the function\n",
    "\n",
    "n_split=3 # Number of folders the cross-validation is going to be done\n",
    " \n",
    "for train_index,test_index in KFold(n_split).split(x): #in order to start the cross-validation for the training set\n",
    "    x_train,x_test=x[train_index],x[test_index]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    model= create_model()\n",
    "    #Early stopping is a method that allows you to specify an arbitrary large number of training epochs... \n",
    "    #...and stop training once the model performance stops improving on a hold out validation dataset\n",
    "    monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-3, patience = 5, verbose = 1, mode = 'auto', \n",
    "                        restore_best_weights = True)\n",
    "    # Assigning to variable history the fitting process\n",
    "    #model.fit(training_dataset_x, training_dataset_y, early_stopping, number of iterations, quantity of data\n",
    "    #used in each epoch, percentage of error for validation (20% this case), if we want to see the process Verbose = 1)\n",
    "    history = model.fit(x_train,\n",
    "          y_train,\n",
    "          #validation_data = (x_test, y_test),\n",
    "          callbacks = [monitor],\n",
    "          epochs=200,\n",
    "          batch_size = 3,\n",
    "          validation_split = 0.2,\n",
    "          verbose=0)\n",
    "    print('Model evaluation ',model.evaluate(x_test,y_test)) # Evalution of the model using the loss function and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 96.56601676045426\n",
      "R^2 on training set is -0.029638320762609416\n",
      "R^2 on testing set is 0.15200261175742713\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Real Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295.135864</td>\n",
       "      <td>306.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304.862457</td>\n",
       "      <td>287.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>277.777374</td>\n",
       "      <td>88.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>241.028320</td>\n",
       "      <td>271.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>331.133179</td>\n",
       "      <td>445.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>344.601776</td>\n",
       "      <td>339.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>332.167328</td>\n",
       "      <td>292.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>319.435883</td>\n",
       "      <td>314.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>323.889252</td>\n",
       "      <td>325.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>278.696289</td>\n",
       "      <td>281.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>253.288193</td>\n",
       "      <td>335.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>313.161713</td>\n",
       "      <td>311.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>329.237946</td>\n",
       "      <td>290.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>351.409363</td>\n",
       "      <td>317.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>367.247650</td>\n",
       "      <td>387.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>381.113800</td>\n",
       "      <td>398.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>353.467438</td>\n",
       "      <td>360.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>275.989471</td>\n",
       "      <td>352.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>289.628235</td>\n",
       "      <td>360.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>363.831970</td>\n",
       "      <td>504.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>368.439453</td>\n",
       "      <td>554.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>398.522827</td>\n",
       "      <td>348.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>351.022949</td>\n",
       "      <td>631.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>293.810394</td>\n",
       "      <td>361.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>277.774017</td>\n",
       "      <td>325.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>342.044464</td>\n",
       "      <td>533.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>386.447968</td>\n",
       "      <td>495.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>404.520569</td>\n",
       "      <td>423.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>390.863251</td>\n",
       "      <td>469.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Real Value\n",
       "0   295.135864      306.40\n",
       "1   304.862457      287.72\n",
       "2   277.777374       88.07\n",
       "3   241.028320      271.31\n",
       "4   331.133179      445.00\n",
       "5   344.601776      339.08\n",
       "6   332.167328      292.83\n",
       "7   319.435883      314.77\n",
       "8   323.889252      325.61\n",
       "9   278.696289      281.02\n",
       "10  253.288193      335.41\n",
       "11  313.161713      311.64\n",
       "12  329.237946      290.35\n",
       "13  351.409363      317.21\n",
       "14  367.247650      387.04\n",
       "15  381.113800      398.78\n",
       "16  353.467438      360.04\n",
       "17  275.989471      352.80\n",
       "18  289.628235      360.87\n",
       "19  363.831970      504.04\n",
       "20  368.439453      554.16\n",
       "21  398.522827      348.65\n",
       "22  351.022949      631.52\n",
       "23  293.810394      361.71\n",
       "24  277.774017      325.97\n",
       "25  342.044464      533.19\n",
       "26  386.447968      495.90\n",
       "27  404.520569      423.49\n",
       "28  390.863251      469.91"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# Prediction for the test set\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Root squared error between prediction and the real values of LMP from the test set\n",
    "score = np.sqrt(mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "# Prediction for the training set\n",
    "pred_train = model.predict(x_train)\n",
    "\n",
    "# R^{2} returns a value which represents the relation betwen the data\n",
    "print(\"R^2 on training set is {}\".format(r2_score(y_train, pred_train)))\n",
    "print(\"R^2 on testing set is {}\".format(r2_score(y_test, pred)))\n",
    "\n",
    "# Showing the prediction and the real values for the LMP in the test set\n",
    "pred = pd.DataFrame(pred)\n",
    "pred.columns = ['Prediction']\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.columns = ['Real Value']\n",
    "results = pd.concat([pred,y_test], axis =1)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x189a2150cc8>]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualization for the preformance between the training set an its validation set,\n",
    "#This helps to see when the model is overfitting\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "plt.figure()\n",
    "plt.plot(loss_values, 'k', label = 'training_loss')\n",
    "plt.plot(val_loss_values, 'r', label = 'val training loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313.815308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276.938751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>248.215622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>294.508667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>303.905060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>383.837036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>404.414459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>393.082489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>375.153534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>300.539337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Forecast\n",
       "0   313.815308\n",
       "1   276.938751\n",
       "2   248.215622\n",
       "3   294.508667\n",
       "4   303.905060\n",
       "..         ...\n",
       "74  383.837036\n",
       "75  404.414459\n",
       "76  393.082489\n",
       "77  375.153534\n",
       "78  300.539337\n",
       "\n",
       "[79 rows x 1 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_f = data.iloc[10:, [1,2,26,50]].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_f = min_max_scaler.fit_transform(x_f)\n",
    "\n",
    "forecast = model.predict(x_f)\n",
    "forecast = pd.DataFrame(forecast)\n",
    "forecast.columns = ['Forecast']\n",
    "forecast\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
