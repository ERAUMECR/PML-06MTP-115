{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00022: early stopping\n",
      "22/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 772us/sample - loss: 65.5764 - mean_absolute_error: 54.8790\n",
      "Model evaluation  [65.57640075683594, 54.879]\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n",
      "22/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 69.0956 - mean_absolute_error: 55.6620\n",
      "Model evaluation  [69.09559631347656, 55.661976]\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00024: early stopping\n",
      "22/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 78.1882 - mean_absolute_error: 63.7340\n",
      "Model evaluation  [78.18818664550781, 63.73395]\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00031: early stopping\n",
      "21/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 999us/sample - loss: 85.3609 - mean_absolute_error: 73.5143\n",
      "Model evaluation  [85.36089324951172, 73.51431]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import HoverTool\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input,Dense, Subtract, Add, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.linear_model import Lasso\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# The models were done by hour using all the days of the week\n",
    "data = pd.read_excel(\"C:/Users/ERIC/Desktop/PML-06MTP-115/06MTP 01012020.xlsm\", 1)\n",
    "\n",
    "# dataset for only the first hour\n",
    "x = data.iloc[0:87, [1,2,26,50]].values\n",
    "y = data.iloc[0:87, 74].values\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 0) #try random_state = 42\n",
    "\n",
    "#Standarization of the data\n",
    "'''\n",
    "sc = StandardScaler()\n",
    "std_x_train = sc.fit_transform(x_train)\n",
    "std_x_test = sc.fit_transform(x_test)\n",
    "'''\n",
    "# Normalization of the data\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x = min_max_scaler.fit_transform(x)\n",
    "\n",
    "def create_model():\n",
    "    # The next model is a sequential one, that means the layers are structured sequantially. \n",
    "    \n",
    "    # Input layer with 4 inputs --> day of the week, demand, generation and the forecast for that day\n",
    "    input_tensor = Input(shape=(x.shape[1],))\n",
    "    layer_drop = Dropout(0.5)\n",
    "    \n",
    "    # First hidden layer --> 100 neurons, relu as activation function...receives the input\n",
    "    hidden_layer = Dense(100, activation = 'relu', kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(input_tensor) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop = Dropout(0.5) # Dropout certain amount of neurons helping to reduce overfitting\n",
    "    #Dropout makes the model does not rely on certain neurons making changes in the information processing\n",
    "    \n",
    "    # Second hidden layer --> 50 neurons, relu as activation function... receives the first hidden layer\n",
    "    hidden_layer1 = Dense(50, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop1 = Dropout(0.5)\n",
    "    \n",
    "    # Third hidden layer --> 50 neurons, relu as activation function... receives the second hidden layer\n",
    "    hidden_layer2 = Dense(50, activation = 'relu',kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer1) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop2 = Dropout(0.5)\n",
    "    \n",
    "    # Fourth hidden layer --> 25 neurons, relu as activation function... receives the third hidden layer\n",
    "    hidden_layer3 = Dense(25, activation = 'relu', kernel_constraint=maxnorm(3),#Make better results with Dropout\n",
    "                     kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01),#To avoid Over-fitting\n",
    "                     activity_regularizer=regularizers.l1(0.01))(hidden_layer2) #Regularize the wieghts to have better accuracy\n",
    "    layer_drop3 = Dropout(0.5)\n",
    "    \n",
    "    # 1 ouput ... Receives the last hidden layer\n",
    "    output_tensor = Dense(1)(hidden_layer3)\n",
    "    \n",
    "    # Here the model is created... receiving the four inputs and 1 output\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    \n",
    "    # Here the model is compiled. Adama is the optimizer in which the learning rate is specified\n",
    "    # The loss function measures helps in optimizing the parameters of the neural networks\n",
    "    # The metrics could be an array of measurements but for this case Mean Absolut error is used because is a Regression \n",
    "    model.compile(optimizer= Adam(0.003),  loss='mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "    return model # the model is returned as a part of the function\n",
    "\n",
    "n_split=2 # Number of folders the cross-validation is going to be done\n",
    " \n",
    "for train_index,test_index in KFold(n_split).split(x): #in order to start the cross-validation for the training set\n",
    "    x_train,x_test=x[train_index],x[test_index]\n",
    "    y_train,y_test=y[train_index],y[test_index]\n",
    "    model= create_model()\n",
    "    #Early stopping is a method that allows you to specify an arbitrary large number of training epochs... \n",
    "    #...and stop training once the model performance stops improving on a hold out validation dataset\n",
    "    monitor = EarlyStopping(monitor = 'val_loss', min_delta = 1e-3, patience = 5, verbose = 1, mode = 'auto', \n",
    "                        restore_best_weights = True)\n",
    "    # Assigning to variable history the fitting process\n",
    "    #model.fit(training_dataset_x, training_dataset_y, early_stopping, number of iterations, quantity of data\n",
    "    #used in each epoch, percentage of error for validation (20% this case), if we want to see the process Verbose = 1)\n",
    "    history = model.fit(x_train,\n",
    "          y_train,\n",
    "          #validation_data = (x_test, y_test),\n",
    "          callbacks = [monitor],\n",
    "          epochs=200,\n",
    "          batch_size = 3,\n",
    "          validation_split = 0.2,\n",
    "          verbose=0)\n",
    "    print('Model evaluation ',model.evaluate(x_test,y_test)) # Evalution of the model using the loss function and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 104.28077825001255\n",
      "R^2 on training set is 0.08035747939586702\n",
      "R^2 on testing set is -0.22659490452556486\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Real Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328.269379</td>\n",
       "      <td>325.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>299.729065</td>\n",
       "      <td>281.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270.698212</td>\n",
       "      <td>335.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>313.187653</td>\n",
       "      <td>311.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325.478302</td>\n",
       "      <td>290.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>343.944397</td>\n",
       "      <td>317.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>357.672852</td>\n",
       "      <td>387.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>369.960999</td>\n",
       "      <td>398.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>351.814240</td>\n",
       "      <td>360.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>285.460754</td>\n",
       "      <td>352.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>298.143250</td>\n",
       "      <td>360.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>351.336517</td>\n",
       "      <td>504.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>355.868439</td>\n",
       "      <td>554.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>381.557129</td>\n",
       "      <td>348.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>347.294769</td>\n",
       "      <td>631.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>308.614960</td>\n",
       "      <td>361.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>287.592834</td>\n",
       "      <td>325.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>333.329437</td>\n",
       "      <td>533.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>369.717010</td>\n",
       "      <td>495.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>385.864685</td>\n",
       "      <td>423.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>395.346558</td>\n",
       "      <td>469.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Real Value\n",
       "0   328.269379      325.61\n",
       "1   299.729065      281.02\n",
       "2   270.698212      335.41\n",
       "3   313.187653      311.64\n",
       "4   325.478302      290.35\n",
       "5   343.944397      317.21\n",
       "6   357.672852      387.04\n",
       "7   369.960999      398.78\n",
       "8   351.814240      360.04\n",
       "9   285.460754      352.80\n",
       "10  298.143250      360.87\n",
       "11  351.336517      504.04\n",
       "12  355.868439      554.16\n",
       "13  381.557129      348.65\n",
       "14  347.294769      631.52\n",
       "15  308.614960      361.71\n",
       "16  287.592834      325.97\n",
       "17  333.329437      533.19\n",
       "18  369.717010      495.90\n",
       "19  385.864685      423.49\n",
       "20  395.346558      469.91"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# Prediction for the test set\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "# Root squared error between prediction and the real values of LMP from the test set\n",
    "score = np.sqrt(mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "# Prediction for the training set\n",
    "pred_train = model.predict(x_train)\n",
    "\n",
    "# R^{2} returns a value which represents the relation betwen the data\n",
    "print(\"R^2 on training set is {}\".format(r2_score(y_train, pred_train)))\n",
    "print(\"R^2 on testing set is {}\".format(r2_score(y_test, pred)))\n",
    "\n",
    "# Showing the prediction and the real values for the LMP in the test set\n",
    "pred = pd.DataFrame(pred)\n",
    "pred.columns = ['Prediction']\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.columns = ['Real Value']\n",
    "results = pd.concat([pred,y_test], axis =1)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e2b0e5ddc8>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualization for the preformance between the training set an its validation set,\n",
    "#This helps to see when the model is overfitting\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "plt.figure()\n",
    "plt.plot(loss_values, 'k', label = 'training_loss')\n",
    "plt.plot(val_loss_values, 'r', label = 'val training loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320.693756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296.195801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>266.252930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300.115753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307.603271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>366.404388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>384.595886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>395.814117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>382.612732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>322.492554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Forecast\n",
       "0   320.693756\n",
       "1   296.195801\n",
       "2   266.252930\n",
       "3   300.115753\n",
       "4   307.603271\n",
       "..         ...\n",
       "74  366.404388\n",
       "75  384.595886\n",
       "76  395.814117\n",
       "77  382.612732\n",
       "78  322.492554\n",
       "\n",
       "[79 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_f = data.iloc[10:, [1,2,26,50]].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_f = min_max_scaler.fit_transform(x_f)\n",
    "\n",
    "forecast = model.predict(x_f)\n",
    "forecast = pd.DataFrame(forecast)\n",
    "forecast.columns = ['Forecast']\n",
    "forecast\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
